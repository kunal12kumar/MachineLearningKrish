{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3667e1d-e663-41e9-95aa-deaeaa015a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this we will use bag of words method to change the words into vector\n",
    "# for that we first import a dataset on which we work\n",
    "# and then change the data set into a table with the help of panda then \n",
    "# lower all the word and then do stemming of that word after that remove stopwords furthur \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a13bf43-6958-4050-9fc1-af2d23a46ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing panda \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeceb1a-ef92-4d8d-a95a-bf77a413c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './emai_spam.csv'\n",
    "\n",
    "try:\n",
    "    table = pd.read_csv(file_path, encoding='utf-8',names=[\"label\",\"message\"])  # Default encoding\n",
    "except UnicodeDecodeError:\n",
    "    table = pd.read_csv(file_path, encoding='latin1',sep=',',names=[\"label\",\"message\",\"one\", \"two\", \"three\"])  # Fallback encoding\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc01ee-9b67-4ef4-a53b-7a218f16731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11c6fc-defb-4afe-a1b3-adef97df9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e35b15-35b8-43b7-b8c2-659c369b7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3554a8-1d6c-4151-8027-d2e966d2fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing message in to a set \n",
    "# print(table['message'])\n",
    "message=table['message']\n",
    "print(message)\n",
    "print(type(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675549e-a6bf-4072-8d36-5478d7e31acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for stemming import porterStemmer \n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "# now import fro stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ae31a-c807-46ea-9486-18747070782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now changing the sentences into the words\n",
    "# so, import words and also do it lower so , we cant get furthur same word in the vocubulary\n",
    "newmessage=[]\n",
    "from nltk.tokenize import word_tokenize\n",
    "for i in range(len(message)):\n",
    "    stemwords=[]\n",
    "    words=word_tokenize(message[i].lower())\n",
    "    print(words)\n",
    "    # first we filter the stopwords and stopword works on each word \n",
    "    # for w in words:\n",
    "    #     if w not in set(stopwords.words('english')):\n",
    "    #         newmessage.append(w)\n",
    "    #     print(newmessage)\n",
    "   \n",
    "\n",
    "# for w in message:\n",
    "#     word=word_tokenize(w.lower())\n",
    "#     for t in word:\n",
    "#         word=stemmer.stem(t)\n",
    "#     if word not in set(stopwords.words):\n",
    "#         newmessage.append(word)\n",
    "            \n",
    "# print(newmessage)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322b235-7b3b-4484-9c00-8d7af234ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470911c6-05c7-41d2-abf3-3b28c00ab224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f7957-74e8-4b32-87ee-4fd259e59d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe26570-9258-4e49-8fca-5f7840e691e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436d0ab-44fb-4cba-96e8-5a0dd29847f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb60d2-37bd-4f39-9c8e-1d6cac52a3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0e0b4-0cf9-476a-b092-24db544691f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea48d97-56a0-45e8-a092-926854199430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cf0e4-e965-4cad-b5b1-ec808440817d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
